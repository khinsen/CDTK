% This file is part of the Crystallographic Data Toolkit and
% distributed under the CeCILL-C licence. See the file LICENCE
% for the full text of this licence.

\documentclass[11pt]{article}
\usepackage{a4}
\usepackage{pdfsync}

\newcommand{\authors}[1]{#1\hspace{3mm}}
\newcommand{\name}[2]{#2, #1}
\newcommand{\And}{, }
\newcommand{\btitle}[1]{{#1,}}
\newcommand{\journal}[4]{#1, #2:#3, #4}


\newcommand{\vect}[1]{{\bf #1}}
\newcommand{\mat}[1]{{\bf #1}}

\newcommand{\va}{\vect{a}}
\newcommand{\vb}{\vect{b}}
\newcommand{\vq}{\vect{q}}
\newcommand{\vr}{\vect{r}}
\newcommand{\vs}{\vect{s}}
\newcommand{\vt}{\vect{t}}

\newcommand{\mU}{\mat{U}}

\begin{document}

{\parindent=0mm

{\Large
A Physicist's Guide to Crystallographic Data
}

\vspace{5mm}

{\large Konrad Hinsen$^{a, b}$}\\
\\
$^a$Centre de Biophysique Mol\'eculaire, CNRS UPR 4301
\footnote{Affiliated with the University of Orl\'eans}\\
Rue Charles Sadron\\
45071 Orl\'eans Cedex 2\\
France\\
\\
$^b$Synchrotron Soleil, Saint Aubin, B.P. 48\\
91192 Gif sur Yvette Cedex\\
France\\
\\
E-mail: hinsen@cnrs-orleans.fr\\
}
\date{}

\vspace{15mm}

\begin{abstract}
  This tutorial explains as much of crystallographers' jargon and
  conventions as is required to interpret crystallographic data
  such as the structure factor files published in the Protein
  Data Bank (PDB). It also explains how such data is represented
  in the Crystallographic Data Toolkit (CDTK), a Python library for
  working with crystallographic data.
\end{abstract}

\newpage
\begin{sloppy}

\section{Units}

Crystallographers measure lengths in {\AA}ngstr{\"om}s (\AA) and angles
in degrees. CDTK uses the same ``atomic SI'' unit system as the
Molecular Modelling Toolkit (MMTK), meaning that distances are
measured in nm and angles in radians.

The module \texttt{CDTK.Units} contains a large collection of unit
conversion factors from and to CDTK's internal units. It is a good
habit to use these factors in Python scripts to indicate the unit
of all input quantities. For example:

\begin{verbatim}
from CDTK import Units

length_1 = 2.5*Units.Ang  # Angstrom
length_2 = 0.5*Units.nm   # nanometer
big_length = 300.*Units.m # meter

angle_1 = 90.*Units.deg   # degrees
angle_2 = 1.3*Units.rad   # radians
\end{verbatim}

The same factors can be used for printing results in the desired units:

\begin{verbatim}
from CDTK import Units

print "the length is %f Angstrom" % (length/Units.Ang)
\end{verbatim}


\section{Crystals}

\subsection{The unit cell}

An ideal crystal is an arrangement of molecules that is periodic in
the three dimensions of space. Its basic motif is the \textit{unit cell},
whose most general shape is a parallelepiped defined by the three
\textit{lattice vectors} $\va_i$, $i=1, 2, 3$.
In PDB files, the shape of the unit cell is described
in terms of the six parameters
\begin{eqnarray}
a &=& |\va_1| \nonumber \\
b &=& |\va_2| \nonumber \\
c &=& |\va_3| \nonumber \\
\alpha &=& \arccos \va_2\cdot\va_3 \nonumber \\
\beta  &=& \arccos \va_1\cdot\va_3 \nonumber \\
\gamma &=& \arccos \va_1\cdot\va_2 \nonumber
\end{eqnarray}
that are given in the \texttt{CRYST1} record.
These six parameters define the shape of the unit cell, but not its
orientation in space. The orientation is defined by the convention
that $\va_1$ is parallel to the $x$-axis and that $\va_2$
lies in the $x$-$y$-plane.

In CDTK, the unit cell is defined by the class
\texttt{CDTK.Crystal.UnitCell}. The class constructor can either be
called with three vector arguments, defining the lattice vectors, or
with six number arguments that correspond to $a$, $b$, $c$, $\alpha$,
$\beta$, and $\gamma$. All CDTK routines that expect a unit cell
argument will also accept an MMTK universe object instead.

\subsection{Fractional and Cartesian coordinates}

Points in the unit cell can of course be identified by their Cartesian
coordinates in space. However, it is often practical to use
\textit{fractional coordinates} instead. Fractional coordinates
describe a point by displacements from the origin along the lattice
vectors. A point defined by the fractional coordinates $(x_1, x_2, x_3)$
has Cartesian coordinates $\vect{r} = \sum_{i=1}^3 x_i\va_i$.
For points inside the unit cell, the fractional coordinates are in the
range $0 <= x_i < 1$.

Conversion between fractional and Cartesian coordinates is provided by
CDTK's \texttt{UnitCell} class (and also by MMTK's universe classes).
The methods \texttt{fractionalToCartesian} and
\texttt{cartesianToFractional} convert one point, whereas the methods
\texttt{fractionalToCartesianMatrix} and
\texttt{cartesianToFractionalMatrix} return the $3 \times 3$
conversion matrix.

\subsection{Symmetry}

Symmetry operations are geometrical operations (translations,
rotations, reflections, inversions, and combinations thereof) that
leave a given crystal unchanged. All crystals share three basic
symmetry operations: translations along the three lattice vectors
$\va_i$.

Most crystals have additional symmetry operations that are defined by
its \textit{space group}. There are in total 230 space groups, but
only 65 of them can occur in crystals of biological macromolecules
because reflections and inversions are not admitted due to the
chirality of the molecules. In a PDB file, the space group of the
crystal is indicated in the \texttt{CRYST1} record by its name (e.g.
\texttt{P 21 21 21} or \texttt{C 2}). The set of symmetry operations
for a given space group can be looked up in tables. CDTK provides a
table containing all 230 space groups. This table is accessible as
\texttt{CDTK.SpaceGroups.space\_groups} and takes the form of a
dictionary that maps space group names or space group numbers (unique
numbers have been assigned by convention) to the corresponding space
group object.

A space group object stores the list of symmetry operations. Each
symmetry operation is represented by a rotation matrix $\mat{D}$ and a
translation vector $\vt$ and specifies that the point $\vr' =
\mat{D}\cdot \vr + \vt$ is equivalent to point $\vr$. The first
element of the symmetry operation list is always the identity
operation ($\mat{D}=\mat{1}$, $\vt=\vect{0}$).

The symmetry operations defined by the space group reduce the amount
of information required to describe the contents of the unit cell. If
the space group has $N$ symmetry operations, the number of independent
atom specifications is reduced by a factor of $N$. A subset of the
unit cell from which all the other atoms can be reconstructed using
symmetry operations is called an \textit{asymmetric unit}. This subset
is of course not unique. The atom records in a PDB file describe an
asymmetric unit.

\section{Structure factors}

The central quantity in the description of X-ray scattering from
crystals is the \textit{structure factor} defined by
\begin{equation}
\label{eq:sf}
F(\vs) = \sum_k f_k(|\vs|) e^{2\pi i\vs\cdot\vr_k},
\end{equation}
where $\vr_k$ is the position of atom $k$ and $f_k(|\vs|)$ is its
\textit{atomic scattering factor}. The summation is performed over all
atoms in the crystal.

The atomic scattering factor describes the electron cloud around an
atom and depends on its chemical element and its ionization state. For
numerical calculations, it is most commonly approximated by a sum of
four Gaussians plus a constant:
\begin{equation}
f(s) = \sum_{i=1}^5 a_i e^{-b_i s^2}
\end{equation}
with $b_5 = 0$. The parameters of this approximation have been tabulated
\cite{CromerMann}. In CDTK, this table is available in the form of the
dictionary
\texttt{CDTK.AtomicScatteringFactors.atomic\_scattering\_factors}.

Since the atomic scattering factor is the Fourier transform of the
electron density of a single atom, the structure factor defined
by Eq.~(\ref{eq:sf}) is the Fourier transform of the electron density
of the whole crystal. Note that physicists would write it in terms
of the vector $\vq = 2\pi\vs$.


\subsection{Bragg reflections}

For an ideal crystal, the structure factor defined by
Eq.~(\ref{eq:sf}), being the Fourier transform of a periodic function,
is non-zero only at discrete points in reciprocal space. These points
are known as \textit{Bragg reflections} (usually just called
``reflections''). They lie on the \textit{reciprocal lattice} and are
given by
\begin{equation}
\vs_{hkl} = h \vb_1 + k \vb_2 + l \vb_3
\end{equation}
where $h, k, l$ are integer numbers called the \textit{Miller indices}
of a reflection and $\vb_i$ are the reciprocal basis vectors defined by
\begin{equation}
\va_i \cdot \vb_j = \delta_{ij}.
\end{equation}
Moreover, the summation in Eq.~(\ref{eq:sf}) can be restricted to the
atoms in the unit cell for an ideal crystal.

The quantity measured in a standard crystallographic experiment is the
square of the magnitude of the structure factor at the reciprocal
lattice points, i.e.
\begin{equation}
I(\vs_{hkl}) = \left| F(\vs_{hkl}) \right|^2,
\end{equation}
which is called the \textit{intensity} of the reflection $\vs_{hkl}$.

The quantity $d_{hkl}=1/|\vs_{hkl}|$ is called the \textit{resolution}
of a reflection. When a crystal structure is described as ``at 2~\AA\ 
resolution'', this means that there were observable reflections up to
$|\vs|=0.5 \mbox{ \AA}^{-1}$.
\begin{quote}
\textbf{Watch out: ``high resolution'' means large $|\vs|$ and thus small $d$;
a resolution of 1~\AA\ is higher than a resolution of 2~\AA!}
\end{quote}

In practice there is also a lower limit to the resolution of the
available reflections, meaning that the result of a crystallographic
experiment consists of the intensities $I(\vs_{hkl})$ for the
reflections in the range $1/d_{\mbox{low}} \leq \vs_{hkl} \leq
1/d_{\mbox{high}}$. $d_{\mbox{low}}$ and $d_{\mbox{high}}$ are
specified as the \textit{resolution range} in a PDB file (in the
\texttt{REMARK   3} section).

The mmCIF structure factor files available for many structures from
the PDB contain $I(\vs_{hkl})$ (mmCIF label \texttt{intensity\_meas})
or $\sqrt{I(\vs_{hkl})}$ (mmCIF label \texttt{F\_meas} or
\texttt{F\_meas\_au}) for the reflections in the specified resolution
range. However, not all reflections are given explicitly, because the
number of independent reflections is reduced by symmetry:
\begin{enumerate}
\item
In the absence of anomalous scattering, the atomic scattering factors
$f_k(|\vs|)$ are real and the structure factor has the symmetry
$F(-\vs) = F^{*}(\vs)$.
\item
The symmetry operations of the space group also apply in reciprocal
space. A symmetry relation defined by ($\mat{D}$, $\vt$) in real space
implies that $F(\mat{D}^T\cdot\vs) = F(\vs) \exp(-2\pi i \vs\cdot\vt)$.
\item
If the space group has symmetry operations with non-zero translations,
the intensities of certain reflections must vanish. These reflections
are called \textit{systematic absences}.
\end{enumerate}
A structure factor file usually lists only a minimal set of
independent reflections. However, the choice of these reflections is
not unique.

\vspace{3mm}

In CDTK, the class \texttt{Reflection} represents a single reflection
defined by its Miller indices. The class \texttt{ReflectionSet}
represents the spherical shell in reciprocal space that corresponds to
a particular crystallographic experiment. A \texttt{ReflectionSet} stores
only a minimal set of reflections explicitly, and it provides iteration
over this minimal set. However, it can also provide a \texttt{Reflection}
object for any set of Miller indices inside the spherical shell.

Data defined for each reflection (intensities, structure factors,
structure factor amplitudes) are not stored in a
\texttt{ReflectionSet}, but in separate classes
(\texttt{ExperimentalIntensities}, \texttt{ExperimentalAmplitudes},
\texttt{StructureFactor}, \texttt{ModelAmplitudes},
\texttt{ModelIntensities}) that store a reference to a
\texttt{ReflectionSet}. The reason for this is that there are usually
several data sets for a single \texttt{ReflectionSet} object. In a
typical workflow, parsing a reflection file yields a
\texttt{ReflectionSet} and an associated
\texttt{ExperimentalIntensities} or \texttt{ExperimentalAmplitudes}
object. Then a \texttt{StructureFactor} object is generated from
a model and compared to the experimental data.

\subsection{Crystallographic models}

Real biomolecular crystals are not perfectly periodic. The arrangement
of the molecules in the different copies of the unit cell varies due
to static disorder (the molecules have somewhat different
configurations in each copy unit cell), crystal defects (mostly
missing molecules whose absence causes deformations in the
neighbouring unit cells), and thermal motion. As a consequence, the
structure factor in Eq.~(\ref{eq:sf}) is non-zero for points in
reciprocal space outside the reciprocal lattice; this is known as
\textit{diffuse scattering}. The energy that goes into diffuse
scattering is also lost to the Bragg reflections, whose intensity is
reduced by destructive interference between the contributions from
unit cell copies with slightly different conformations. This
attenuation of the Bragg peaks becomes more important with increasing
$|\vs|$.

Standard crystallographic models represent non-ideal crystals by an
average unit cell containing an average conformation plus Gaussian
fluctuations around the average. Eq.~(\ref{eq:sf}) is replaced by
\begin{equation}
\label{eq:model_sf}
F(\vs) = \sum_k f_k(|\vs|) e^{-2\pi^2 \vs\cdot\mU_k\cdot\vs} e^{2\pi i\vs\cdot<\vr_k>},
\end{equation}
with a summation over the atoms in the unit cell.
The additional factor $\exp(-2\pi^2 \vs\cdot\mU_k\cdot\vs)$,
called the \textit{Debye-Waller factor}, describes the fluctuation
of an atom in an harmonic potential well. The symmetric tensor $\mU_k$
describes the position fluctuations of atom~$k$; it is given by
\begin{equation}
\mU_k = \left<  (\vr_k-<\vr_k>) (\vr_k-<\vr_k>) \right>.
\end{equation}
Its elements are called \textit{anisotropic displacement parameters}
(ADPs). Their use in biomolecular crystallography is relatively
recent, because high-resolution data is required to fit nine
parameters per atom (three for the position, six for the
fluctuations). For fitting lower-resolution data, the fluctuation
tensor is assumed to be isotropic, reducing it to a single parameter
known as the \textit{B factor} and given by
\begin{equation}
B_k = \frac{8\pi^2}{3} \mbox{tr } \mU_k.
\end{equation}

Several points are important to note:
\begin{enumerate}
\item
  Eq.~(\ref{eq:model_sf}) is an approximation. The conformational
  variability of the crystal need not be described by Gaussian
  fluctuations.
\item
  The Debye-Waller factor was originally derived as a model for
  thermal fluctuations in an harmonic potential, and the B~factor is
  often called ``temperature factor'' for this reason. However, the
  conformational variability it is made to describe in practice is
  only partly due to thermal fluctuations.
\item
  The refinement process includes restraints on the parameters which
  are necessary for obtaining reasonable models without any reliable
  information about the phases of the structure factors.
  The restraints on the average positions are derived from the known
  chemical structure of the building blocks of the molecules and are
  thus physically reasonable. The restraints on the fluctuation
  parameters are chosen much more arbitrarily with the main goal
  of stabilizing the convergence of the fit procedure.
\item
  Crystallographers are much more interested in the conformation than
  in the fluctuations. A lot of effort has gone into obtaining ever
  better structural models, but B factors and ADPs are still mostly
  considered an inevitable nuisance (because no reasonable agreement
  between model and experiment is possible without them) rather than
  parameters of direct physical interest.
\end{enumerate}
For these reasons, the information about the fluctuations in the fitted
crystallographic models is much less reliable than the atomic positions
and should be interpreted with care.

A complementary approach to modelling conformational variability is
the use of multiple position/fluctuation sets for some atoms. In this
case, each set carries a weight called the \textit{occupancy}; the sum
of the occupancies over all position/fluctuation sets for one atom
must be~1.

\vspace{3mm}

CDTK permits the calculation of structure factors from standard
crystallographic models for a given \texttt{ReflectionSet}.
There are three ways to specify the model:
\begin{itemize}
\item
as an iterator over the atoms in the unit cell, yielding a tuple
of (atom\_id, chemical element, position, fluctuation tensor, occupancy)
for each atom:
{\small
\begin{verbatim}
sf = StructureFactor.fromUnitCellAtoms(reflection_set,
                       (atom, atom.symbol, atom.position(),
                        atom.temperature_factor/(8.*N.pi**2),
                        atom.occupancy)
                       for atom in unit_cell.atomList())
\end{verbatim}
}
\item
as an iterator over the atoms in the asymmetric unit, yielding a tuple
of (atom\_id, chemical element, position, fluctuation tensor, occupancy)
for each atom:
{\small
\begin{verbatim}
sf = StructureFactor.fromAsymmetricUnitAtoms(reflection_set,
                         (atom, atom.symbol, atom.position(),
                          adps[atom], atom.occupancy)
                         for atom in asu.atomList())
\end{verbatim}
}
\item
as an MMTK universe plus an optional MMTK \texttt{ParticleTensor} object
specifying the fluctuation tensors:
{\small
\begin{verbatim}
sf = StructureFactor.fromUniverse(reflection_set, universe, adps)
\end{verbatim}
}
\end{itemize}
The first item in each of the atom iterators is an arbitrary object
that serves as a unique identifier for the atom. It is not used
in the calculation of structure factors, but it becomes important
in the \texttt{RefinementEngine} classes that share the same
iterator interface.

\subsection{Comparing models to experimental data}

The most commonly used similarity criterion for comparing a model
to an experimental data set is the R~factor, defined by
\begin{equation}
R = \frac{\sum_{hkl}
    \left| |F_{\mbox{model}}(\vs_{hkl})|-|F_{\mbox{experiment}}(\vs_{hkl})| \right|}
    {\sum_{hkl} |F_{\mbox{experiment}}(\vs_{hkl})|}.
\end{equation}
The summation is performed over the minimal set of unique reflections.
The experimental structure factor amplitudes are simply the square roots
of the measured intensities.

In CDTK, the R~factor is calculated by
\begin{verbatim}
r = exp_amplitudes.rFactor(model_sf)
\end{verbatim}
Since experimental intensities are usually not normalized, it is often
preferable to allow a scale factor between the two data sets that
minimizes the R~factor. This is written as
\begin{verbatim}
r, scale = exp_amplitudes.rFactorWithScale(model_sf)
\end{verbatim}

In some situations, it is of interest to compare data sets allowing not only
a constant factor between them, but also a global Debye-Waller factor.
Fitting the model
\begin{equation}
\label{eq:scaling}
F_1(\vs_{hkl}) = k F_2(\vs_{hkl}) e^{-2\pi^2 \vs_{hkl}\cdot\mU\cdot\vs_{hkl}}
\end{equation}
with the fit parameters $k$ and $\mU$ is known as \textit{scaling} $F_2$
to $F_1$. In CDTK, it is performed by
\begin{verbatim}
scaled_sf, k, u = model_sf.scaleTo(exp_amplitudes, iterations)
\end{verbatim}
The integer parameter \verb/iterations/ indicates the number of iterations
of the non-linear fit (using the Gauss-Newton algorithm) to be performed.
A first approximation is obtained by taking the logarithm of 
Eq.~(\ref{eq:scaling}) and obtaining $k_0, \mU_0$ from the resulting
linear least-squares problem. With the default of \verb/iterations=0/,
this is the return value. Otherwise, the indicated number of iterations
are performed to solve the non-linear least-squares problem.


\section{Structure refinement}

The iterative procedure (partly automatic, partly manual) of
constructing a model of the type given by Eq.~(\ref{eq:model_sf}) and
fitting it to the experimental data is known as \textit{structure
  refinement}. The main difficulty in this procedure is the lack of
experimental information about the phase of the structure factor. If
the phase were known, a Fourier transform of the measured structure
factor would yield an electronic density map, whose visual inspection
would permit the construction of an initial model. This problem and
various approaches to a solution are discussed in the crystallographic
literature. In the following, we describe only the final stages of
structure refinement (a reasonably good model is supposed to be known
already), for which CDTK contains some functionality.

The methods described in this section are implemented in the CDTK
modules \texttt{Refinement} and \texttt{SubsetRefinement}. These
modules implement various \textit{refinement engines}. A refinement
engine stores the current model parameters (which can be modified of
course) and the structure factor amplitudes to which the model is
fitted. It calculates a \textit{target function} (the function that
the refinement process aims to minimize) and its derivatives with
respect to the amplitudes or with respect to the model parameters.
There are several refinement engine classes that implement different
models and target functions. Note that the refinement engines do not
implement minimization or sampling algorithms for the model
parameters.

\subsection{Bayesian inference}

The most suitable theoretical framework for structure refinement is
Bayesian inference. This approach is based on a specific
interpretation of probability: probability measures the degree of
belief in a hypothesis, on a scale from~0 to~1. In the case of
structure refinement, a hypothesis consists of a specific combination
of parameters in a model.

Bayesian inference consists of a series of steps in which the
probability distribution of the hypotheses is improved by considering
more and more available information. The starting point is a
\textit{prior probability} distribution $P_{\mbox{prior}}(X)$ that
reflects basic knowledge (or assumptions) about the model, e.g. the
size of the unit cell, the symmetry of the crystal, the sequence of
the peptide chains, the structure of amino acids, etc. $X$ stands for
all the parameters of the model. New evidence, in the form of experimental
observations, is integrated through Bayes' theorem,
\begin{equation}
P_{\mbox{posterior}}(X|D) = \frac{P(D|X)}{\int dX\,P(D|X)} P_{\mbox{prior}}(X)
\end{equation}
which gives the \textit{posterior} probability in view of the data
$D$, $P_{\mbox{posterior}}(X|D)$, as a function of the prior probability
$P_{\mbox{prior}}(X)$ and the \textit{conditional probability} $P(D|X)$
that the data $D$ are observed if the parameters are known to be $X$.
This conditional probability is also called the \textit{likelihood}
of $X$ given the data $D$, denoted by $L(X|D)$. For a model to be
useful in Bayesian inference, it must be a probabilistic model in which
$P(D|X)$ is non-zero for a certain range of $D$. In other words, the model
must describe the sources of uncertainties in the experiment, such as
experimental errors.

\subsection{Maximum-likelihood optimization}

In general, the posterior probability is the most accurate description
of the available information about the paramters $X$. If it is a
sufficiently narrow distribution around a single maximum $X_0$, the
parameter set $X_0$ can be considered the ``best'' one. If furthermore
$P_{\mbox{prior}}(X)$ takes the form of restraints that are either
fulfilled or not, then the ``best'' solution is given by the maximum
of the likelihood function subject to the restraints. This approach is
known as the maximum-likelihood method. In practice, the condition that
the posterior probability is localized around a single maximum is
rarely verified.

\subsection{Structure factor likelihoods}

The two central inputs to the Bayesian method applied to
crystallographic data are the prior probability (which can involve
restraints on the structure, or be written as a Boltzmann distribution
based on a force field) and the likelihood function. The latter
describes the probability density of the observables for a given set
of parameters. For the standard crystallographic model given by
Eq.~(\ref{eq:model_sf}), the parameters are average positions and ADPs
of the atoms, and the observables are the structure factor amplitudes
for the Bragg reflections. The likelihood function must of course
include the model given Eq.~(\ref{eq:model_sf}), but in addition it
contains an error model that describes the distribution of deviations
from the ideal relation (\ref{eq:model_sf}). These deviations can take
the form of errors in the parameters and/or errors in the structure factor
values.

The likelihood functions currently used in crystallographic structure
refinement are all based on the assumption that the probability
distributions for the structure factor values $F(\vs_k)$ for different
reflections $\vs_k$ are independent. This assumption is certainly
wrong, but introduced because it greatly simplifies the mathematical
treatment. The various likelihood functions differ in the error model
and in simplifying assumptions made about the importance of the various
errors.

\subsubsection{Observational errors}

Observational errors are caused by imperfections of the experiment.
They are generally assumed to b desribed by a Gaussian distribution of
the observed intensities $I$ around the ``true'' value
$I^{\mbox{true}}$ with variance $\sigma_I^2$.
\begin{equation}
P_{\mbox{obs-I}}(I; I^{\mbox{true}}, \sigma_I) =
     \frac{1}{\sqrt{2\pi\sigma_I^2}}
           \exp \left( - \frac{I-I^{\mbox{true}}}{2 \sigma_I^2}\right)
\end{equation}
The diffraction experiment yields for each reflection both $I$
(interpreted as a realization of the random variable) and an
estimation of $\sigma_I$ based on an analysis of the shape of the
reflection images (which are of course not perfect points) and their
surroundings.

For mathematical convenience, the error model is most often applied to
the structure factor amplitudes instead of the intensities, yielding a
Gaussian distribution of the observed intensities $A$ around the
``true'' value $A^{\mbox{true}}$ with variance $\sigma^2$:
\begin{equation}
\label{gaussian_amplitude}
P_{\mbox{obs}}(A; A^{\mbox{true}}, \sigma) =
      \frac{1}{\sqrt{2\pi\sigma^2}}
           \exp \left( - \frac{A-A^{\mbox{true}}}{2 \sigma^2}\right)
\end{equation}
If $I >> \sigma_I$, the error model for the amplitudes is equivalent
to the one for the intensities, with $A^{\mbox{true}} =
\sqrt{I^{\mbox{true}}}$ and $\sigma = \sigma_I/2 A^{\mbox{true}}$.
CDTK uses these relations when converting between experimental
intensities and amplitudes. There are, however, more elaborate
procedures for converting intensities and their variances to
amplitudes and variances, which perform better for small $I/\sigma_I$
and in particular for negative $I$ (see e.g. \cite{FrWi1978}).

\vspace{3mm}

If observational errors are the only source of uncertainty in the
model, the total likelihood function is a product of the terms
(\ref{gaussian_amplitude}) over all reflections and $A^{\mbox{true}} =
A^{\mbox{model}}$. Maximizing this function is equivalent to
minimizing its negative logarithm, which takes the form
\begin{equation}
\label{eq:lsq_target}
LLK = \frac{1}{N_{\mbox{r}}}
      \sum_k \left[ \frac{\left( A_k - f A_k^{\mbox{model}}\right)^2}
                         {2 \sigma_k^2}
                    - \frac{1}{2} \log{2\pi\sigma_k^2}
             \right]
\end{equation}
where $N_{\mbox{r}}$ is the number of reflections.
The scale factor $f$ must be introduced because the experimental
amplitudes are measured on an arbitrary scale. The optimal value of
$f$ is the one that minimizes (\ref{eq:lsq_target}); it is given by
\begin{equation}
f = \frac{\sum_k A_k  A_k^{\mbox{model}}/\sigma_k^2}
         {\sum_k \left(A_k^{\mbox{model}}/\sigma_k\right)^2}.
\end{equation}
The use of this model is known as \textit{least-squares refinement},
implemented in \texttt{CDTK.Refinement.LeastSquaresRefinementEngine}.
Least-squares refinement used to be the standard refinement technique
in biomolecular crystallography, until it was realized that in most
situations, the model errors discussed below are much more important
than the observational errors. Nevertheless, least-squares refinement
remains a valid choice in the final stages of refinement, when a good
model is already available and the model errors are small.


\subsubsection{Model errors}

Model errors describe uncertainties in the parameters entering into
the model for the structure factors given by Eq.~(\ref{eq:model_sf}),
as well as phenomena not described by that model at all. The most
commonly considered model errors are (1) incompleteness of the model
(there are atoms in the crystal that are not contained in the model
for various reasons) and (2) errors in the atomic parameters
(position, ADP, occupancy). It should be noted that in the framework
of Bayesian inference, it is inconsistent to include uncertainties in
the parameters being optimized into the error model. The uncertainties
of these parameters are given by the width of the peak in the
posterior probability distribution function that corresponds to the
maximum-likelihood values of the parameters, i.e. they are a result
of the inference procedure and not an input to it. It is therefore
inconsistent to use an error model based on positional uncertainties
in structure refinement, although that same error model is acceptable
for other tasks, such as the estimation of phases.

A common feature of the commonly used error models is that they yield
a Gaussian distribution for the (complex) structure factor values
$F(\vs_k)$. In the absence of symmetry constraints on $F(\vs_k)$
(so-called \textit{acentric} reflections), the probability
distribution of $F(\vs_k)$ is a two-dimensional Gaussian. For
\textit{centric} reflections, defined as those $\vs_k$ for which at
least one symmetry operation of the space group yields
$\mat{D}^T\cdot\vs_k = -\vs_k$, the phase can take only two values
(given by $\phi_1 = \pi \vs_k\cdot\vt$ and $\phi_2 = \phi_1+\pi$) and
the distribution of $F(\vs_k)$ is a one-dimensional Gaussian. The
probability distributions for the structure factor amplitudes are
obtained by integrating over the phases (for acentric reflections) or
by summing over the two possible phases (for centric reflections),
yielding the \textit{Rice distribution},
\begin{equation}
P_{\mbox{model}}(A; A_0, \Sigma) = \frac{A}{\Sigma}
                      \exp\left(-\frac{A^2+A_0^2}{2\Sigma}\right)
                      I_0\left(\frac{A A_0}{\Sigma}\right)
\end{equation}
for acentric reflections and
\begin{equation}
P_{\mbox{model}}(A; A_0, \Sigma) = \sqrt{\frac{2}{\pi\Sigma}}
                      \exp\left(-\frac{A^2+A_0^2}{2\Sigma}\right)
                      \cosh\left(\frac{A A_0}{\Sigma}\right)
\end{equation}
for centric reflections, where $A$ is the measured structure factor
amplitude. The parameter
\begin{equation}
A_0 = \alpha f A^{\mbox{model}}
\end{equation}
is the mean structure factor value under the probability distribution
that describes the uncertainties due to the model errors. It depends
on the model structure factor amplitude $A^{\mbox{model}}$, the scale factor
$f$ (see the discussion above), and a factor $\alpha$ that depends on
the error model. The parameter
\begin{equation}
\Sigma = \left\{
  \begin{array}{cl}
    \frac{1}{2} \epsilon \beta & \mbox{(acentric)} \\
    \epsilon \beta &\mbox{(centric)}
  \end{array}
\right. 
\end{equation}
describes the width of the structure factor amplitude distribution. It
depends on the integer number $\epsilon$, which is equal to the number
of symmetry relations that map the reflection vector $\vs_k$ onto
itself, and a factor $\beta$ that again depends on the error model.
With this notation, an error model consists of a specification of
$\alpha$ and $\beta$ for each reflection $\vs_k$.

\vspace{2mm}
\textbf{Incompleteness}

For a model in which M out of the N atoms are represented by positions
and ADPs, whereas the remaining N-M atoms have unknown positions and are
assumed to be uniformly distributed in the asymmetric unit, the
error model is specified by
\begin{eqnarray}
\alpha(\vs_k) &=& 1 \\
\beta(\vs_k) &=& \sum_{j=M+1}^N f_j^2(|\vs_k|) \exp(-B_j |\vs_k|^2/2),
\end{eqnarray}
where $B_j$ is the (isotropic) B-factor of atom $j$. It can either
be given an fixed assumed value, or it can be refined along with the
parameters of the model (\ref{eq:model_sf}).

\vspace{2mm}
\textbf{Incompleteness and errors in the atomic parameters}

If in addition to the incompleteness of the model it is assumed that
the positions and ADPs of all atoms have errors, the total error model
is specified by
\begin{eqnarray}
\alpha(s) &=& \left< \exp\left[-\Delta B s^2/4\right]
                       \cos\left[2\pi \vs \cdot \Delta \vr\right]
              \right>_{\Delta B, \Delta \vr}
\\
\beta(s) &=& \sum_{k=1}^M f_k^2(s) \exp(-B_k s^2/2) (1-\alpha(s)^2)
           + \sum_{k=M+1}^N f_k^2(s) \exp(-B_k s^2/2)
\end{eqnarray}
These expressions, which depend only on the length of the scattering
vector $\vs_k$, can be derived under the assumption that the uncertainties
of the positions have an identical and isotropic distribution for all
atoms. In practice, $\alpha$ and $\beta$ are estimated from a set of
reflections within a given small $s$ range by maximizing the likelihood
function.

\subsubsection{Combining observational and model errors}

If both model errors and observational errors are considered,
the amplitude variable $A$ of the ``model error'' likelihood function
is the ``true'' amplitude of the ``observational error'' likelihood
function, which thus becomes itself a random variable. The total
likelihood function is then given by the integral
\begin{equation}
P_{\mbox{total}}(A; A_0, \Sigma, \sigma) = 
   \int_0^{\infty} \, d A^{\mbox{true}} \,
      P_{\mbox{obs}}(A; A^{\mbox{true}}, \sigma) \,
      P_{\mbox{model}}(A^{\mbox{true}}; A_0, \Sigma)
\end{equation}
Since this integral cannot be calculated analytically, and since its
numerical evaluation is too expensive, various approximations are used
in practice. For $A_0 >> \Sigma$, the Rice distribution is well
approximated by a Gaussian distribution. The total likelihood function
is then close to a Gaussian with a width of $\Sigma+\sigma^2$. The
approximation
\begin{equation}
P_{\mbox{total}}(A; A_0, \Sigma, \sigma) = 
    P_{\mbox{model}}(A; A_0, \Sigma+\sigma^2),
\end{equation}
used in the refinement program REFMAC \cite{MuVaDo1997}, is obviously
good in this case, but it is also good if $\sigma^2 << \Sigma$, i.e.
if the model error dominates the observational error.

This approximation is implemented in the class
\texttt{CDTK.Refinement.MLRefinementEngine}, which by default
uses incompleteness as the only model error. Other model errors
can be implemented by subclassing and redefining the method that
calculates $\alpha$ and $\beta$. The target function of this
refinement engine is
\begin{equation}
\label{eq:ml_target}
LLK = -\frac{1}{N_{\mbox{r}}}
      \sum_k \log P_{\mbox{model}}(A_k; A_{0, k}, \Sigma_k+\sigma_k^2)
\end{equation}
Like in the case of least-squares refinement, the optimal scale factor
$f$ is obtained by minimizing the target function with respect to $f$.
Unlike for least-squares refinement, this optimization must be
performed numerically, and is thus relatively expensive in terms
of CPU time. For this reason, it is not performed automatically at
each evaluation of the target function, but must be invoked explicitly
by calling the method \texttt{optimizeScaleFactor()}.


\end{sloppy}

\begin{thebibliography}{99}

\bibitem{CromerMann}
International Tables for Crystallography, Vol. C\\
ISBN 978-1-4020-1900-5 \\
doi:10.1107/97809553602060000103

\bibitem{FrWi1978}
\authors{\name{S.}{French}\And\name{K.S.}{Wilson}}
\btitle{On the Treatment of Negative Intensity Observations}
\journal{Acta Cryst. A}{34}{517--525}{1978}

\bibitem{MuVaDo1997}
\authors{\name{G.N.}{Murshudov}, \name{A.A.}{Vagin}\And\name{E.J.}{Dodson}}
\btitle{Refinement of Macromolecular Structures by the
        Maximum-Likelihood Method }
\journal{Acta Cryst. D}{53}{240--255}{1997}

\end{thebibliography}

\end{document}
